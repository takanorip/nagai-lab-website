### 概要
一般に「ロボット」は心つまり感情のない存在と考えられている．しかし，ロボットが人間社会に受け入れられていくためには，相手の感情を理解・共感し，行動するということが必要である．本研究では，人とロボットが共感し合う未来を目指して，高次な社会的感情をロボットが獲得するための感情モデルの研究を行っている．感情モデルを作ることを通して，人の感情のメカニズムを明らかにするとともに，ロボットに感情モデルを実装し，人を理解し自身の感情を表出する人工物を開発する．

### 感情モデル
認知科学や神経科学の文献を参考に以下のようなモデルを構築した．

##### 1層：生得的反応層
刺激を受け，身体的反応を行う

##### 2層：経験層
刺激を受け，経験に基づいて生得的反応を抑制・強化する

##### 3層：予測層
次元圧縮された身体的反応（情動）と刺激に基づいて原因推論・未来予測を行っている．

#### モデルの詳細
第1 層は反射的に反応する層であり，時間的に処理が最も早いが，エラーも多くなる．それに対し，第2 層では過去の記憶にアクセスするため，第1 層からの遅延はあるが，経験に基づいて評価するため，エラーを減らすことができる．この1 層2 層から出力された一次表出を次元圧縮したものが情動と定義している．こうして得られた情動と入力信号を使って原因推論をし，未来予測を行う．未来予測の結果を使って最適な行動を出力する．このときの情報がカテゴリとして意識へと昇ったものが感情として認知される．

![提案する感情モデルの図]()
**提案する感情モデル**

### 一層目の実装
提案モデルの一層目の実装を，Recurrent Attention Modelを用いて行った．

##### 入力
画像刺激 (International Affective Picture System)

##### 出力
情動値 ( Valence/快度・Arousal/覚醒度 )
アテンション位置

##### 学習方法
教師あり学習
Mini-batch法，batch size 100，2000epoch，アテンション回数 10

#### 学習結果
テストセットを入力とした出力は正解データとモデルデータの誤差がarousal:0.48，valence:0.46であり，個人差程度の誤差であった． また，学習したアテンションは人の顔や黄色などの明るい色，またはエッジを良く見る傾向がみられた．

![Recurrent Attention Modelの図]()
**Recurrent Attention Model**

### 情動反応の検証
一層目をロボットに実装し，人とのコミュニケーションの様子を観察した．
この際ロボットの情動値に対応した表情を作り込みで実装した．
その結果，ある特定の物体を見せた際には快，他の物体を見せた際には不快といったようなある種好みのようなものを表出したり，情動伝染のような反応を見せた．
さらに画像内のどのような特徴に反応しているのかを解析するため，色に対する反応の解析と顔表情に対する反応の解析を行った．

#### 解析結果
##### 色空間に対する反応
HSV色空間の画像を入れ，快度を出力した．その結果，黄色や赤や白に対しては快で，緑や青や紫の色画像に不快反応を示した．これは，幼児の好みと同じ結果となっている．
##### 顔表情に対する反応
表情画像を入れ，各情動値の出現頻度を解析した．その結果笑顔だと快傾向になり，怒りだと不快傾向になるという情動伝染のような現象が示された．

<iframe width="560" height="315" src="https://www.youtube.com/embed/rW_GwwUDHJc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
